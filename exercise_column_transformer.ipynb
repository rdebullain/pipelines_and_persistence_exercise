{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import and Encode the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"aug_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, encode the ordinal feature using mapping to transform categorical features into numerical features (since the model takes only numerical input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dictionaries of ordinal features\n",
    "\n",
    "relevent_experience_map = {\n",
    "    'Has relevent experience':  1,\n",
    "    'No relevent experience':    0\n",
    "}\n",
    "\n",
    "experience_map = {\n",
    "    '<1'      :    0,\n",
    "    '1'       :    1, \n",
    "    '2'       :    2, \n",
    "    '3'       :    3, \n",
    "    '4'       :    4, \n",
    "    '5'       :    5,\n",
    "    '6'       :    6,\n",
    "    '7'       :    7,\n",
    "    '8'       :    8, \n",
    "    '9'       :    9, \n",
    "    '10'      :    10, \n",
    "    '11'      :    11,\n",
    "    '12'      :    12,\n",
    "    '13'      :    13, \n",
    "    '14'      :    14, \n",
    "    '15'      :    15, \n",
    "    '16'      :    16,\n",
    "    '17'      :    17,\n",
    "    '18'      :    18,\n",
    "    '19'      :    19, \n",
    "    '20'      :    20, \n",
    "    '>20'     :    21\n",
    "} \n",
    "\n",
    "last_new_job_map = {\n",
    "    'never'        :    0,\n",
    "    '1'            :    1, \n",
    "    '2'            :    2, \n",
    "    '3'            :    3, \n",
    "    '4'            :    4, \n",
    "    '>4'           :    5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dictionaries of ordinal features\n",
    "def encode(df_pre):\n",
    "    df_pre['relevent_experience'] = df_pre['relevent_experience'].map(relevent_experience_map)\n",
    "    df_pre['last_new_job'] = df_pre['last_new_job'].map(last_new_job_map)\n",
    "    df_pre['experience'] = df_pre['experience'].map(experience_map)\n",
    "  \n",
    "    return df_pre\n",
    "\n",
    "df = encode(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define Sets of Columns to be Transformed in Different Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['city_development_index','relevent_experience', 'experience','last_new_job', 'training_hours']\n",
    "cat_cols = ['gender', 'enrolled_university', 'education_level', 'major_discipline', 'company_size', 'company_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create Pipelines for Numerical and Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax of the pipeline is: Pipeline(steps = [(‘step name’, transform function), …])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numerical features, I perform the following actions:\n",
    "\n",
    "1. **SimpleImputer**: Fill in the missing values with the mean of that column.\n",
    "2. **MinMaxScaler**: Scale the values to range from 0 to 1 (this will affect regression performance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categorical features, perform the following actions:\n",
    "\n",
    "1. **SimpleImputer**: Fill in the missing values with the most frequent value of that column.\n",
    "2. **OneHotEncoder**: Split into multiple numerical columns for model training. (`handle_unknown='ignore'` is specified to prevent errors when it finds an unseen category in the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('scale',MinMaxScaler())\n",
    "])\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('one-hot',OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create ColumnTransformer to Apply the Pipeline for Each Column Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax of the ColumnTransformer is: ColumnTransformer(transformers=[(‘step name’, transform function,cols), …])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass numerical columns through the numerical pipeline and pass categorical columns through the categorical pipeline created in step 3.\n",
    "\n",
    "remainder=’drop’ is specified to ignore other columns in a dataframe.\n",
    "\n",
    "n_job = -1 means that we'll be using all processors to run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "col_trans = ColumnTransformer(transformers=[\n",
    "    ('num_pipeline',num_pipeline,num_cols),\n",
    "    ('cat_pipeline',cat_pipeline,cat_cols)\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Add a Model to the Final Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the logistic regression model in this example.\n",
    "\n",
    "Create a new pipeline to commingle the ColumnTransformer in step 4 with the logistic regression model. Using a pipeline in this case because the entire dataframe must pass the ColumnTransformer step and modeling step, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf_pipeline = Pipeline(steps=[\n",
    "    ('col_trans', col_trans),\n",
    "    ('model', clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Display the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax for this is display(pipeline name):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;col_trans&#x27;,\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[(&#x27;num_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scale&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  [&#x27;city_development_index&#x27;,\n",
       "                                                   &#x27;relevent_experience&#x27;,\n",
       "                                                   &#x27;experience&#x27;, &#x27;last_new_job&#x27;,\n",
       "                                                   &#x27;training_hours&#x27;]),\n",
       "                                                 (&#x27;cat_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;one-hot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;gender&#x27;,\n",
       "                                                   &#x27;enrolled_university&#x27;,\n",
       "                                                   &#x27;education_level&#x27;,\n",
       "                                                   &#x27;major_discipline&#x27;,\n",
       "                                                   &#x27;company_size&#x27;,\n",
       "                                                   &#x27;company_type&#x27;])])),\n",
       "                (&#x27;model&#x27;, LogisticRegression(random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>Pipeline(steps=[(&#x27;col_trans&#x27;,\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[(&#x27;num_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scale&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  [&#x27;city_development_index&#x27;,\n",
       "                                                   &#x27;relevent_experience&#x27;,\n",
       "                                                   &#x27;experience&#x27;, &#x27;last_new_job&#x27;,\n",
       "                                                   &#x27;training_hours&#x27;]),\n",
       "                                                 (&#x27;cat_pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;one-hot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;gender&#x27;,\n",
       "                                                   &#x27;enrolled_university&#x27;,\n",
       "                                                   &#x27;education_level&#x27;,\n",
       "                                                   &#x27;major_discipline&#x27;,\n",
       "                                                   &#x27;company_size&#x27;,\n",
       "                                                   &#x27;company_type&#x27;])])),\n",
       "                (&#x27;model&#x27;, LogisticRegression(random_state=0))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;col_trans: ColumnTransformer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for col_trans: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(n_jobs=-1,\n",
       "                  transformers=[(&#x27;num_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;impute&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;scale&#x27;, MinMaxScaler())]),\n",
       "                                 [&#x27;city_development_index&#x27;,\n",
       "                                  &#x27;relevent_experience&#x27;, &#x27;experience&#x27;,\n",
       "                                  &#x27;last_new_job&#x27;, &#x27;training_hours&#x27;]),\n",
       "                                (&#x27;cat_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;impute&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;one-hot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 [&#x27;gender&#x27;, &#x27;enrolled_university&#x27;,\n",
       "                                  &#x27;education_level&#x27;, &#x27;major_discipline&#x27;,\n",
       "                                  &#x27;company_size&#x27;, &#x27;company_type&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">num_pipeline</label><div class=\"sk-toggleable__content \"><pre>[&#x27;city_development_index&#x27;, &#x27;relevent_experience&#x27;, &#x27;experience&#x27;, &#x27;last_new_job&#x27;, &#x27;training_hours&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content \"><pre>SimpleImputer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;MinMaxScaler<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">?<span>Documentation for MinMaxScaler</span></a></label><div class=\"sk-toggleable__content \"><pre>MinMaxScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">cat_pipeline</label><div class=\"sk-toggleable__content \"><pre>[&#x27;gender&#x27;, &#x27;enrolled_university&#x27;, &#x27;education_level&#x27;, &#x27;major_discipline&#x27;, &#x27;company_size&#x27;, &#x27;company_type&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content \"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content \"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content \"><pre>LogisticRegression(random_state=0)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('col_trans',\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[('num_pipeline',\n",
       "                                                  Pipeline(steps=[('impute',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scale',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  ['city_development_index',\n",
       "                                                   'relevent_experience',\n",
       "                                                   'experience', 'last_new_job',\n",
       "                                                   'training_hours']),\n",
       "                                                 ('cat_pipeline',\n",
       "                                                  Pipeline(steps=[('impute',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('one-hot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  ['gender',\n",
       "                                                   'enrolled_university',\n",
       "                                                   'education_level',\n",
       "                                                   'major_discipline',\n",
       "                                                   'company_size',\n",
       "                                                   'company_type'])])),\n",
       "                ('model', LogisticRegression(random_state=0))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import set_config\n",
    "\n",
    "set_config(display='diagram')\n",
    "display(clf_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Split the Data into Train and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split 20% of the data into a test set like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[num_cols+cat_cols]\n",
    "y = df['target']\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the pipeline for the train set and use that fitted pipeline for the test set to prevent data leakage from the test set to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Pass Data through the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the syntax for this: pipeline_name.fit, pipeline_name.predict, pipeline_name.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pipeline.fit`: Passes data through a pipeline and fits the model.\n",
    "- `pipeline.predict`: Uses the model trained during `pipeline.fit` to predict new data.\n",
    "- `pipeline.score`: Gets a score of the model in the pipeline (accuracy of logistic regression in this example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score: 0.7625260960334029\n"
     ]
    }
   ],
   "source": [
    "clf_pipeline.fit(X_train, y_train)\n",
    "# preds = clf_pipeline.predict(X_test)\n",
    "score = clf_pipeline.score(X_test, y_test)\n",
    "print(f\"Model score: {score}\") # model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Save the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax for this is `joblib.dumb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the joblib library to save the pipeline for later use, so you don’t need to create and fit the pipeline again. When you want to use a saved pipeline, just load the file using joblib.load like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# save pipeline to file \"pipe.joblib\"\n",
    "joblib.dump(clf_pipeline,\"pipe.joblib\")\n",
    "\n",
    "# load pipeline when you want to use\n",
    "same_pipe = joblib.load(\"pipe.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Find the Best Hyperparameter Sets: Add a Pipeline to Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search is a method you can use to perform hyperparameter tuning. It helps you find the optimum parameter sets that yield the highest model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the tuning parameters and their range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary of tuning parameters (hyperparameters): { ‘tuning parameter’ : ‘possible value’, … }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, find the best penalty type and C of a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "grid_params = {'model__penalty' : ['none', 'l2'],\n",
    "               'model__C' : np.logspace(-4, 4, 20)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the pipeline to Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV(model, tuning parameter, …)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pipeline has a model step as the final step, so we can input the pipeline directly to the GridSearchCV function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score of train set: 0.7657574470937899\n",
      "Best parameter set: {'model__C': 0.23357214690901212, 'model__penalty': 'l2'}\n",
      "Test Score: 0.7627870563674322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "100 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.75061987        nan 0.75061987        nan 0.75061987\n",
      "        nan 0.75061987        nan 0.75629655        nan 0.76197308\n",
      "        nan 0.76471342        nan 0.76510502        nan 0.76575745\n",
      "        nan 0.76503962        nan 0.7645829         nan 0.76484389\n",
      "        nan 0.76497435        nan 0.76484384        nan 0.7649091\n",
      "        nan 0.7649091         nan 0.7649091         nan 0.7649091\n",
      "        nan 0.7649091         nan 0.7649091 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs = GridSearchCV(clf_pipeline, grid_params, cv=5, scoring='accuracy')\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Score of train set: \"+str(gs.best_score_))\n",
    "print(\"Best parameter set: \"+str(gs.best_params_))\n",
    "print(\"Test Score: \"+str(gs.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting up Grid Search, you can fit Grid Search with the data and see the results. Let's see what the code is doing:\n",
    "\n",
    "- `.fit`: Fits the model and tries all sets of parameters in the tuning parameter dictionary.\n",
    "- `.best_score_`: The highest accuracy across all sets of parameters.\n",
    "- `.best_params_`: The set of parameters that yield the best score.\n",
    "- `.score(X_test, y_test)`: The score when trying the best model with the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to adjust the current pipeline a little"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to know which scaling method will work best for my data between MinMaxScaler and StandardScaler. I add a step StandardScaler in the num_pipeline. The rest doesn't change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline2 = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('minmax_scale', MinMaxScaler()),\n",
    "    ('std_scale', StandardScaler()),\n",
    "])\n",
    "\n",
    "col_trans2 = ColumnTransformer(transformers=[\n",
    "    ('num_pipeline',num_pipeline2,num_cols),\n",
    "    ('cat_pipeline',cat_pipeline,cat_cols)\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    n_jobs=-1)\n",
    "    \n",
    "clf_pipeline2 = Pipeline(steps=[\n",
    "    ('col_trans', col_trans2),\n",
    "    ('model', clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Perform Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In grid search parameters, specify the steps to skip and set their value to passthrough. Since MinMaxScaler and StandardScaler should not perform at the same time, use a list of dictionaries for the grid search parameters. E.g., [{case 1},{case 2}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using a list of dictionaries, grid search will perform a combination of every parameter in case 1 until complete. Then, it will perform a combination of every parameter in case 2. So there is no case where MinMaxScaler and StandardScaler are used together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_step_params = [{'col_trans__num_pipeline__minmax_scale': ['passthrough']},\n",
    "                    {'col_trans__num_pipeline__std_scale': ['passthrough']}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Grid Search and print the results (like a normal grid search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score of train set: 0.7650395379944643\n",
      "Best parameter set: {'col_trans__num_pipeline__minmax_scale': 'passthrough'}\n",
      "Test Score: 0.7627870563674322\n"
     ]
    }
   ],
   "source": [
    "gs2 = GridSearchCV(clf_pipeline2, grid_step_params, scoring='accuracy')\n",
    "gs2.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Score of train set: \"+str(gs2.best_score_))\n",
    "print(\"Best parameter set: \"+str(gs2.best_params_))\n",
    "print(\"Test Score: \"+str(gs2.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best case is minmax_scale : ‘passthrough’, so StandardScaler is the best scaling method for this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Find the Best Hyperparameter Sets and the Best Data Preparation Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best hyperparameter sets and the best data preparation method by adding tuning parameters to the dictionary of each case of the data preparation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {'model__penalty' : ['none', 'l2'],\n",
    "               'model__C' : np.logspace(-4, 4, 20)}\n",
    "               \n",
    "grid_step_params2 = [{**{'col_trans__num_pipeline__minmax_scale': ['passthrough']}, **grid_params},\n",
    "                    {**{'col_trans__num_pipeline__std_scale': ['passthrough']}, **grid_params}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid_params will be added to both case 1 (skip MinMaxScaler) and case 2 (skip StandardScalerand)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge dictionary using this syntax: merge_dict = {**dict_1,**dict_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score of train set: 0.7669317430876349\n",
      "Best parameter set: {'col_trans__num_pipeline__minmax_scale': 'passthrough', 'model__C': 0.004832930238571752, 'model__penalty': 'l2'}\n",
      "Test Score: 0.7640918580375783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "200 fits failed out of a total of 400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"c:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\16476\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.75061987        nan 0.75061987        nan 0.75349061\n",
      "        nan 0.76275601        nan 0.76693174        nan 0.76614896\n",
      "        nan 0.76627934        nan 0.76543108        nan 0.76490901\n",
      "        nan 0.76490903        nan 0.76497431        nan 0.76464806\n",
      "        nan 0.76471332        nan 0.76471332        nan 0.76484382\n",
      "        nan 0.76484382        nan 0.76484382        nan 0.76484382\n",
      "        nan 0.76484382        nan 0.76484382        nan 0.75061987\n",
      "        nan 0.75061987        nan 0.75061987        nan 0.75061987\n",
      "        nan 0.75629655        nan 0.76197308        nan 0.76471342\n",
      "        nan 0.76510502        nan 0.76575745        nan 0.76503962\n",
      "        nan 0.7645829         nan 0.76484389        nan 0.76497435\n",
      "        nan 0.76484384        nan 0.7649091         nan 0.7649091\n",
      "        nan 0.7649091         nan 0.7649091         nan 0.7649091\n",
      "        nan 0.7649091 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# perform Grid Search and print the results (like a normal grid search)\n",
    "gs3 = GridSearchCV(clf_pipeline2, grid_step_params2, scoring='accuracy')\n",
    "gs3.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Score of train set: \"+str(gs3.best_score_))\n",
    "print(\"Best parameter set: \"+str(gs3.best_params_))\n",
    "print(\"Test Score: \"+str(gs3.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best parameter set using .best_params_. As minmax_scale : ‘passthrough’, so StandardScaler is the best scaling method for this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all grid search cases using .cv_results_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_col_trans__num_pipeline__minmax_scale</th>\n",
       "      <th>param_model__C</th>\n",
       "      <th>param_model__penalty</th>\n",
       "      <th>param_col_trans__num_pipeline__std_scale</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034625</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'col_trans__num_pipeline__minmax_scale': 'pas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035888</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.011861</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'col_trans__num_pipeline__minmax_scale': 'pas...</td>\n",
       "      <td>0.750489</td>\n",
       "      <td>0.750734</td>\n",
       "      <td>0.750734</td>\n",
       "      <td>0.750734</td>\n",
       "      <td>0.750408</td>\n",
       "      <td>0.750620</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032155</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'col_trans__num_pipeline__minmax_scale': 'pas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.035982</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.011009</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'col_trans__num_pipeline__minmax_scale': 'pas...</td>\n",
       "      <td>0.750489</td>\n",
       "      <td>0.750734</td>\n",
       "      <td>0.750734</td>\n",
       "      <td>0.750734</td>\n",
       "      <td>0.750408</td>\n",
       "      <td>0.750620</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033266</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'col_trans__num_pipeline__minmax_scale': 'pas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.050299</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.011707</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1438.449888</td>\n",
       "      <td>l2</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>{'col_trans__num_pipeline__std_scale': 'passth...</td>\n",
       "      <td>0.768102</td>\n",
       "      <td>0.767700</td>\n",
       "      <td>0.752692</td>\n",
       "      <td>0.762480</td>\n",
       "      <td>0.773573</td>\n",
       "      <td>0.764909</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.032805</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3792.690191</td>\n",
       "      <td>none</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>{'col_trans__num_pipeline__std_scale': 'passth...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.047058</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.004314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3792.690191</td>\n",
       "      <td>l2</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>{'col_trans__num_pipeline__std_scale': 'passth...</td>\n",
       "      <td>0.768102</td>\n",
       "      <td>0.767700</td>\n",
       "      <td>0.752692</td>\n",
       "      <td>0.762480</td>\n",
       "      <td>0.773573</td>\n",
       "      <td>0.764909</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.033474</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>none</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>{'col_trans__num_pipeline__std_scale': 'passth...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.047456</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.009701</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>passthrough</td>\n",
       "      <td>{'col_trans__num_pipeline__std_scale': 'passth...</td>\n",
       "      <td>0.768102</td>\n",
       "      <td>0.767700</td>\n",
       "      <td>0.752692</td>\n",
       "      <td>0.762480</td>\n",
       "      <td>0.773573</td>\n",
       "      <td>0.764909</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.034625      0.006329         0.000000        0.000000   \n",
       "1        0.035888      0.002077         0.011861        0.001807   \n",
       "2        0.032155      0.002674         0.000000        0.000000   \n",
       "3        0.035982      0.002943         0.011009        0.004184   \n",
       "4        0.033266      0.000643         0.000000        0.000000   \n",
       "..            ...           ...              ...             ...   \n",
       "75       0.050299      0.001175         0.011707        0.000385   \n",
       "76       0.032805      0.002020         0.000000        0.000000   \n",
       "77       0.047058      0.005294         0.010679        0.004314   \n",
       "78       0.033474      0.003093         0.000000        0.000000   \n",
       "79       0.047456      0.003345         0.009701        0.002882   \n",
       "\n",
       "   param_col_trans__num_pipeline__minmax_scale param_model__C  \\\n",
       "0                                  passthrough         0.0001   \n",
       "1                                  passthrough         0.0001   \n",
       "2                                  passthrough       0.000264   \n",
       "3                                  passthrough       0.000264   \n",
       "4                                  passthrough       0.000695   \n",
       "..                                         ...            ...   \n",
       "75                                         NaN    1438.449888   \n",
       "76                                         NaN    3792.690191   \n",
       "77                                         NaN    3792.690191   \n",
       "78                                         NaN        10000.0   \n",
       "79                                         NaN        10000.0   \n",
       "\n",
       "   param_model__penalty param_col_trans__num_pipeline__std_scale  \\\n",
       "0                  none                                      NaN   \n",
       "1                    l2                                      NaN   \n",
       "2                  none                                      NaN   \n",
       "3                    l2                                      NaN   \n",
       "4                  none                                      NaN   \n",
       "..                  ...                                      ...   \n",
       "75                   l2                              passthrough   \n",
       "76                 none                              passthrough   \n",
       "77                   l2                              passthrough   \n",
       "78                 none                              passthrough   \n",
       "79                   l2                              passthrough   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'col_trans__num_pipeline__minmax_scale': 'pas...                NaN   \n",
       "1   {'col_trans__num_pipeline__minmax_scale': 'pas...           0.750489   \n",
       "2   {'col_trans__num_pipeline__minmax_scale': 'pas...                NaN   \n",
       "3   {'col_trans__num_pipeline__minmax_scale': 'pas...           0.750489   \n",
       "4   {'col_trans__num_pipeline__minmax_scale': 'pas...                NaN   \n",
       "..                                                ...                ...   \n",
       "75  {'col_trans__num_pipeline__std_scale': 'passth...           0.768102   \n",
       "76  {'col_trans__num_pipeline__std_scale': 'passth...                NaN   \n",
       "77  {'col_trans__num_pipeline__std_scale': 'passth...           0.768102   \n",
       "78  {'col_trans__num_pipeline__std_scale': 'passth...                NaN   \n",
       "79  {'col_trans__num_pipeline__std_scale': 'passth...           0.768102   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0                 NaN                NaN                NaN   \n",
       "1            0.750734           0.750734           0.750734   \n",
       "2                 NaN                NaN                NaN   \n",
       "3            0.750734           0.750734           0.750734   \n",
       "4                 NaN                NaN                NaN   \n",
       "..                ...                ...                ...   \n",
       "75           0.767700           0.752692           0.762480   \n",
       "76                NaN                NaN                NaN   \n",
       "77           0.767700           0.752692           0.762480   \n",
       "78                NaN                NaN                NaN   \n",
       "79           0.767700           0.752692           0.762480   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0                 NaN              NaN             NaN               41  \n",
       "1            0.750408         0.750620        0.000142               35  \n",
       "2                 NaN              NaN             NaN               41  \n",
       "3            0.750408         0.750620        0.000142               35  \n",
       "4                 NaN              NaN             NaN               41  \n",
       "..                ...              ...             ...              ...  \n",
       "75           0.773573         0.764909        0.007046               10  \n",
       "76                NaN              NaN             NaN               41  \n",
       "77           0.773573         0.764909        0.007046               10  \n",
       "78                NaN              NaN             NaN               41  \n",
       "79           0.773573         0.764909        0.007046               10  \n",
       "\n",
       "[80 rows x 17 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs3.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 80 cases for this example. There's running time and accuracy of each case to consider, since sometimes we may select the fastest model with acceptable accuracy instead of the highest accuracy one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Add a Custom Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from standard data transformation functions such as MinMaxScaler from sklearn, can create own transformation of data.\n",
    "\n",
    "This example creates a class method to encode ordinal features using mapping to transform categorical features into numerical ones. In simple words, we'll change data from text to numbers.\n",
    "\n",
    "First we'll do the required data processing before regression model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class Encode(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Making Dictionaries of ordinal features\n",
    "        self.rel_exp_map = {\n",
    "            'Has relevent experience': 1,\n",
    "            'No relevent experience': 0}\n",
    "            \n",
    "    def fit(self, df, y = None):\n",
    "    \treturn self\n",
    "        \n",
    "    def transform(self, df, y = None):\n",
    "        df_pre = df.copy()\n",
    "        df_pre.loc[:,'rel_exp'] = df_pre['rel_exp'].map(self.rel_exp_map)\n",
    "        return df_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an explanation of what's going on in this code:\n",
    "\n",
    "- Create a class named `Encode` which inherits from the base class `TransformerMixin` from `sklearn`.\n",
    "- Inside the class, there are 3 necessary methods: `__init__`, `fit`, and `transform`.\n",
    "  - `__init__` will be called when a pipeline is created. It is where we define variables inside the class. I created a variable `rel_exp_map` which is a dictionary that maps categories to numbers.\n",
    "  - `fit` will be called when fitting the pipeline. I left it blank for this case.\n",
    "  - `transform` will be called when a pipeline transform is used. This method requires a dataframe (`df`) as an input while `y` is set to `None` by default (it is forced to have a `y` argument).\n",
    "- In `transform`, the dataframe column `rel_exp` will be mapped with the `rel_exp_map`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add this Encode class as a pipeline step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('Encode', Encode()),\n",
    "    ('col_trans', col_trans),\n",
    "    ('model', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can fit, transform, or grid search the pipeline like a normal pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Find the Best Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom transformation that receives a model as an input and performs grid search to find the best model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
